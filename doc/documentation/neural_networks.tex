%------------------------------------------------------
%Author             : Daniel Schembri, Jonathan Schwarz
%University         : Pforzheim University
%Date of last edit  : Wed, 03 Sep 2014 14:12:16 +0200
%Filename           : multithreading_with_posix_pthreads.tex
%------------------------------------------------------

\documentclass[10pt,a4paper,DIV=11]{scrreprt}

%British English
\usepackage[UKenglish]{babel}
%utf8
\usepackage[utf8]{inputenc}

%pseudo-code
\usepackage[boxruled,vlined]{algorithm2e}

%for source code listings
\usepackage{listings}

\usepackage[table]{xcolor}

%tikz
\usepackage{tikz}
\usetikzlibrary{arrows,positioning,fit}

%plots
\usepackage{pgfplots}

%blocks - used by tikz-uml, included before
\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

%<,> in tikz-uml
\usepackage[T1]{fontenc}
\usepackage{tikz-uml}

%subfigure
\usepackage{graphicx}
\usepackage{subfigure}

%prevent figure from floating pictures
\usepackage{float}

%footer & header
\usepackage{fancyhdr}

%push footer down
\usepackage[bottom]{footmisc}

%footer & header
\pagestyle{fancy}
%clean footer & header
\fancyhf{}

%bibtex
\usepackage[square,numbers]{natbib}
\usepackage{gensymb}

%equation
\usepackage[tbtags]{amsmath}
\usepackage{amssymb} 

%table of contents with hyperlinks
%always include as last package
\usepackage{hyperref}

%===========================TITLE PAGE=======================================

%university logo
\titlehead
{
    \includegraphics[width=0.20\textwidth]{files/hspflogo.pdf}\\

    Pforzheim University\\
    School of Engineering\\
}

\subject{Project work}
	
\title
{
    Evolving neutral networks\\
}

\author
{
    by \textbf{Daniel Schembri} - matriculation number: 310026 \\
    and \textbf{Jonathan Schwarz} - matriculation number: 304728
}
\date
{
    Winter term 2013/2014
}
%\today{}}

\publishers
{
    Examiner: Prof Dr Richard Alznauer\\
    Supervisor: Dr Christoph Ussfeller
}


%=========================================GLOBAL SETTINGS=========================================

%footer &header

%\fancyfoot[L]{\textbf{Multi-Threading mit POSIX-pThreads}}
\fancyhead[R]{Page \thepage}
%\fancyhead[L]{\thechapter}

%chapter number and title
\fancyhead[L]{\nouppercase{\leftmark}}
%line
%\renewcommand{\footrulewidth}{0.5 pt}
\usepackage{lmodern}
\addtokomafont{sectioning}{\rmfamily}
\setlength{\parindent}{0mm}

%colour definitions
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.7,0.7,0.7}
%medium gray
\definecolor{mgray}{gray}{0.80}
%light gray
\definecolor{lgray}{gray}{0.97}

%hyperlink settings
%frame around hyperlinks
\hypersetup
{
    colorlinks = false,
    linkcolor = black,
    hypertexnames = false,
    citecolor = green
}

%listing settings
\lstset
{ 
    language=C,                
    basicstyle=\footnotesize\ttfamily,           
    numbers=left,
    stepnumber=5,    
    firstnumber=1,
    numberfirstline=true                 
    numberstyle=\color{black},                 
    numbersep=5pt,                 
    backgroundcolor=\color{white},      
    showspaces=false,             
    showstringspaces=false,         
    showtabs=false,                
    frame=single,                   
    rulecolor=\color{black},       
    tabsize=2,                     
    captionpos=b,                   
    breaklines=true,                
    breakatwhitespace=false,       
    title=\lstname,                    
    keywordstyle=\color{blue},          
    commentstyle=\color{dkgreen}, 
    identifierstyle=\color{black},      
    stringstyle=\color{purple},      
    escapeinside={\%*}{*)},      
    morekeywords={*,...},            
    deletekeywords={...}             
}

%=====================================DOCUMENT START=========================
\begin{document}

\tikzstyle{line}=[draw]
\tikzstyle{arrow}=[draw, -latex] 

%\renewcommand*\contentsname{Content}
%\renewcommand*\listtablename{Tables}
%\renewcommand*\listfigurename{Figures}
%\renewcommand*\bibname{Literature references}

\maketitle
\thispagestyle{empty}
\newpage
{\large\tableofcontents}
\newpage

\chapter{Artifical neural networks}
\section{Biological and mathematical neurons}
The wish to build reproduce human intelligence has been around since the dawn of mankind. In the effort of building truely intelligent systems, thinking about our brain has turned out to be very useful, helping scientists to extent the scope of technical ideas. One of the basic findings of neuron science is a hypohesis, which suggesst that mental acivity consists primarily of electrochemical acivity in large networks of brain cells, or neurons. Hence the name called neuronal networks. \marginpar{\textit{The biological neuron}}
Although their is still not fully understood, we do know that neurons receive input from other neurons and create an output themselves, as soon as the neuron is activated \textit{it fires}. This ouput will again be received by other neurons. Figure \ref{fig:neuron} introduces the different parts of the biological neuron. Branching out from the cell body or Soma, several fibers called dendrites can be observed. The main function of the dendrites is to receive input from up to 100,000 connected neurons. The axon is a single long fiber with a length of 1 cm, what is typically 100 times the diameter of the cell body. As a matter of fact, it can reach up to one meter. The output signals of the neuron are transmitted over the axon via complicated chemical process. The synaptic terminals, which can be found at the end of the terminal are special connections, which can be strengthend or weakend, therefore amplifying or reducing the output signal strength. This modification of signals, which is achieved by the synapses release of chemicals called neurotransmitter, define the behavior of the network, enabling the network to control brain acivity in the short term, and also long-term changes in the connectivity of neurons.

\begin{center}
\begin{figure}
\includegraphics[width=0.8\textwidth,scale=1]{files/neuron.jpg}  
\caption{The parts of a nerve cell or neuron as shown in \cite{NEU}.}
\label{fig:neuron}
\end{figure}
\end{center}


Inspired by his hypothesis, some of the earliest work in the field of Artifical Intelligence aimed on building a similar srucure, a so called artifical neural network. \marginpar{\textit{The artifical neuron}}The general idea of this approach perceives the neuron as a basic Input/Ouput unit, which somehow processes the signals of other neurons and propagades its result further into the network. The funcion of the synpases is simply reproduced by altering each individual input by a  factor which is constantly modified by a certain percentage. This never-ending modificaion of all the input weights represents the learning effect of an artifical neuron. Figure \ref{fig:mathneuron} shows a simple mathematical model of a neuron which was first devised by \cite{NEURONMATH}. The artifical neurons output function is:\\

\begin{equation}
a_j = g(\sum_{i=0}^{} w_{i,j} \cdot a_{i})
\end{equation}

$a_{i}$ is the output of unit ${i}$ and $w_{i,j}$ the wight on the link from unit $i$ to unit $j$ (this unit). 


\begin{figure}
\centering

\begin{tikzpicture}
\node [align=center] (in1) at (-0.5,0) {$a_i$}; 
\node [align=center] (in2) at (-0.3,0.75)   {}; 
\node [align=center] (in3) at (-0.8,1.5) {$a_i = 1$}; 
\node [align=center] (w1) at (0.7,0) {$w_{ij}$}; 
\node [align=center] (w3) at (0.7,1.5) {$w_{0j}$};
\node [align=center] (input) at (2,0.75) {\ \ $\sum_{}^{in_{j}}$}; 
\node [align=center] (function) at (4,0.75) {$\varphi$}; 
\node [align=center] (output) at (6,0.75) {$a_j$}; 
\node [align=center] (o1) at (8.5,0) {};
\node [align=center] (o2) at (8.5,0.75) {};
\node [align=center] (o3) at (8.5,1.5) {};

\node [align=center] (desilinks) at (0,-1) {Input\\ Links}; 
\node [align=center] (desinput) at (1.9,-1) {Input\\ funcion}; 
\node [align=center] (desfunc) at (4,-1) {Activation\\ function}; 
\node [align=center] (desoutput) at (6,-1) {Output}; 
\node [align=center] (desolinks) at (8,-1) {Output\\ links}; 

\node [align=center] (desweight) at (4,2) {$a_j = g(in_j)$}; 
\node [align=center] (desinfunc) at (0.75,2) {\small Bias Weight}; 
\node [align=center] (descneuron) at (6,1.5) {\small Cell body}; 

\node [align=center] (dummy1) at (2.4,0.75) {}; 
\node [align=center] (dummy2) at (5.36,0.75) {}; 

\draw[arrow]	(in1) -- (input);
\draw[arrow]	(in2) -- (input);
\draw[arrow]	(in3) -- (input);

\draw[arrow]	(output) -- (o1);
\draw[arrow]	(output) -- (o2);
\draw[arrow]	(output) -- (o3);

\node[draw=black,fit=(dummy1) (function) (dummy2) ,ellipse] (tmp) {};

\end{tikzpicture}
\caption{A simple mathematical model for a neuron}
\label{fig:mathneuron}
\end{figure}

\subsection{Units, Activity and Training}

The units in a representation of a neural network on a computer are divided into 3 classes, depending on their position in the network. \marginpar{\textit{Layers}}Neurons which reseve input from external sources, e.g. sensors, are called Input units and simply latch  their input into the next layer of neurons. At the other end of the network, the output layer which represents the last layer of the network, can be found. Its output is collected and evaluated by a logic that utilizes the neural network as a black box. In between those layers, a variable amount of so-called hidden layers can be found. They represent the networks \textbf{backbone so lassen?} or center. The complexity of the network increases by the amount of hidden layers. Figure \ref{fig:3layer} shows a three layer (sometimes called two layer, since the input layer does no computation) neural network. 
In order to allow computers quick and easy calculations, weights are often stored in matrices, representing the whole model as a basic mathematical unit. Let $N_{i}$ be a neural network, consisting of $i$ layers: Input,  output and $i-2$ hidden layers. $N_{i}$ can be fully described by $i-1$ matrices $W_{i,j}$ where $i$ is the number of units in the preceding layer, and $j$ the amount of neurons that are connected to any of those $i$ units:
\begin{equation}
W_{i,j} = 
\begin{pmatrix}
w_{1,1} & \cdots & w_{i,1} \\
\vdots & \ddots & \vdots \\
w_{1,j} & \cdots & w_{i,j} \\
\end{pmatrix}
\end{equation}





In addition, the concept of Bias Neurons has proven itself useful. Bias units  \marginpar{\textit{Bias-Units}} are neurons, which don't receive any input signals and have a fixed output of $+ 1$, although the weight on the connection link may be $\pm 1$. The Bias-Unit connected to a link with a positive weight is used to keep Neurons \textit{alive}, if they don't receive a significant input. On the contrary, a negative link may be used to keep a neuron in an inactive state.
Another application ist the implementation of a threshold value on a unit, preventing it from fireing too often.\\ 

As discussed before, the weights of the connections between the neurons represent the 'Intelligence' of the network. The bigger the absolute value of the weight, the greater the influence of a neuron to another. This value can be both positive and negative, as well as neutral \textit{(0)}, meaning that there is currently no influence between the neurons, although there is still a link connecting them. A weight of 0 can be understood as a logical pinch of the link, preventing it from transmitting signals.

\begin{figure}
\centering

\begin{tikzpicture}
\node [draw=red, fill=red, align=center, circle] (i1) at (0,3) {}; 
\node [draw=red, fill=red, align=center, circle] (i2) at (0,2) {}; 
\node [draw=red, fill=red, align=center, circle] (i3) at (0,1) {}; 
\node [draw=red, fill=red, align=center, circle] (i4) at (0,0) {}; 

\node [draw=blue, fill=blue, align=center, circle] (h1) at (2,2.5) {}; 
\node [draw=blue, fill=blue, align=center, circle] (h2) at (2,1.5) {};
\node [draw=blue, fill=blue, align=center, circle] (h3) at (2,0.5) {};

\node [draw=green, fill=green, align=center, circle] (o1) at (4,2) {};
\node [draw=green, fill=green, align=center, circle] (o2) at (4,1) {};

\draw[arrow]	(i1) -- (h1);
\draw[arrow]	(i1) -- (h2);
\draw[arrow]	(i1) -- (h3);

\draw[arrow]	(i2) -- (h1);
\draw[arrow]	(i2) -- (h2);
\draw[arrow]	(i2) -- (h3);

\draw[arrow]	(i3) -- (h1);
\draw[arrow]	(i3) -- (h2);
\draw[arrow]	(i3) -- (h3);

\draw[arrow]	(i4) -- (h1);
\draw[arrow]	(i4) -- (h2);
\draw[arrow]	(i4) -- (h3);

\draw[arrow]	(h1) -- (o1);
\draw[arrow]	(h1) -- (o2);

\draw[arrow]	(h2) -- (o1);
\draw[arrow]	(h2) -- (o2);

\draw[arrow]	(h3) -- (o1);
\draw[arrow]	(h3) -- (o2);

\node[draw=red,fit=(i1) (i2) (i3) (i4),ellipse] (inputLayer) {};
\node[draw=blue,fit=(h1) (h2) (h3) ,ellipse] (hiddenLayer) {};
\node[draw=green,fit=(o1) (o2) ,ellipse] (outputLayer) {};

\node [align=center] (di) at (0,5) {\textcolor{red}Input\\ Layer};
\node [align=center] (dh) at (2,5) {\textcolor{blue}Hidden\\ Layer};
\node [align=center] (do) at (4,5) {\textcolor{green}Output\\ Layer};


\end{tikzpicture}
\caption{A three-layer neural network}
\label{fig:3layer}
\end{figure}

The connection between the input values and the activity level of the neuron is made by the activity function $\varphi$.\marginpar{\textit{Activity}} Different models are obtained depending on the choice of the activity or transfer function. Amongst the most common choices are the linear, binary step and sigmoid function as illustrated in Figure \ref{fig:plots}. The linear function has a threshold $t$, which can be used to avoid low network input (e.g. noise) to be further propagted into the network. The binary step function represents the firing of a pulse down the axon if positive $1$), while $0$ represents no firing. The step function is sometimes defined to jump from $-1$ to $1$. 

Sigmoid functions are widely used amongst network which are to represent cognitive processes such as perception, recoginition, problem solving, etc. .
Both the logistic function as well as the hyperbolic tangent function $\tanh()$ can be used. The main advantage of sigmoid functions are:

\begin{itemize}
\item In contrast with the linear function (without a threshold), the activity level of the function is limited in both the positive and the negative. This means that activity in the network can not spill over unintentionally, which can be caused by recurrent connections.
\item Differentiability
As distinct from the binary step function, it is differntiable at all parts, which as an example, is a requirement of the gradient descent, used by the Backpropagation algorithm (about to be introdced in section \ref{sec:learning}
\end{itemize}


\begin{figure}[H]
\centering
\subfigure[]
{
   \begin{tikzpicture}
		\begin{axis}[
        width=4cm, height=4cm,     % size of the image
        grid = major,
        grid style={dashed, gray!30},
		xmax=1,        
        ymin=-1,
        ymax=1,
        axis background/.style={fill=white},
        ylabel=$a_{j}$,
        xlabel=$in_{j}$]
     
		\addplot[black]{x};
		\end{axis}
	\end{tikzpicture}
\label{fig:plot1}
}

\subfigure[]
{
   \begin{tikzpicture}
		\begin{axis}[
        width=4cm, height=4cm,     % size of the image
        grid = major,
        grid style={dashed, gray!30},
		xmax=1,        
        ymin=-1,
        ymax=1,
        axis background/.style={fill=white},
        ylabel=$a_{j}$,
        xlabel=$in_{j}$]
     
		\addplot[black]{x+2};
		\end{axis}
	\end{tikzpicture}
\label{fig:plot2}
}

\subfigure[]
{
   \begin{tikzpicture}
		\begin{axis}[
        width=4cm, height=4cm,     % size of the image
        grid = major,
        grid style={dashed, gray!30},
		xmax=1,        
        ymin=-1,
        ymax=1,
        axis background/.style={fill=white},
        ylabel=$a_{j}$,
        xlabel=$in_{j}$]
     
		\addplot[black]{x};
		\end{axis}
	\end{tikzpicture}
\label{fig:plot2}
}

	
\caption{Comparison of commonly used activation functions}
\label{fig:plots}
\end{figure}

In order to teach neural networks and enbale them to apply learned behavior in following scenarios, the work with them is divided in a training- and test phase. During the training, the network learns certain behavior by feeding repetitive input to the first layer and observing the output of the network. This can be done in a supervised and unsupervised way. In a supervised training phase, the targeted output of the network is already known and is presented to the network as a \textit{teaching factor}. The network produces output depending on the current weights on its connections and adjusts them acordingly to the margin between the targeted and produced output. Unsupervised learning is necessary in situations, where no reasonable teaching factors are available or the observant is more interested on the performance. Similarity between input incentives and connection weights is the factor, acording to which weight adjustment is done in such models.

\section{Learning}\label{sec:learning}
\subsection{Hebbian learning rule}
The psychologist Donald Olding Hebb proposed on the easiest learning rules with high biological plausibility in \cite{HEBB}:\\

\textit{``Let us assume that the persistence or repetition of a reverberatory activity (or "trace") tends to induce lasting cellular changes that add to its stability.… When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A's efficiency, as one of the cells firing B, is increased.''}\\

In summary: The weight between two units $i$ and $j$ is changed, if both units are active at the same time. The amount of change is set by three factors:

\begin{itemize}
\item The activity level of the sending unit $a_i$.
\item The activity level of the receiving unit $a_j$.
\item A settled and constant paramter $\eta$
\end{itemize}

The weight change $\Delta w_{ij}$ using the hebbian learning rule is shown in equation \eqref{eq:hebb}.
\begin{equation}
\Delta w_{i,j} = \eta \cdot a_i \cdot a_j
\label{eq:hebb}
\end{equation}

One of the major drawbacks of the hebbian rule is the fact, that is can only applied on networks without a hidden layer, and therefore only very simple neural networks.

\subsection{Delta rule}
The delta rule is based on the comparison between a targeted output $t$ and the observed output $o$ and can therefore only be applied with supervised learning.
It can be expressed using equation \eqref{eq:delta1}.
\begin{equation}
\delta = t - o
\label{eq:delta1}
\end{equation}

The following possibilities can be observed:
\begin{itemize}
\item \textbf{The observed output is too low}\\
In order to amplify the output, the weights between neurons is strengthened, provided a positive weight on the connection linking them. Negative weights are weakened.
\item \textbf{The observed output is too high}\\
All connections with positiv weights are weakened, while the ones with negative weights are strengthened 
\item \textbf{Targeted and observed output are equivalent. (= ideal behavior)}\\ There is no need to change the links.
\end{itemize}

The deltas learning rule equation \eqref{eq:delta2} covers all three posiblities, thus ensuring that the changing rate is proportional to the difference between targeted and observed. The learning paramter $\eta$ is again set before the beginning of the learning process and remains constant. The multiplication with the sending units output $a_i$ esures that those connections, that have the greatest influence into the error have the greatest $\delta w_{i,j}$.
\begin{equation}
\Delta w_{i,j} = \eta \cdot \delta \cdot a_i
\label{eq:delta2}
\end{equation}

The simplicity of this learning rules also comes at great cost: The comparison only allows us to adjust connections which connect to the rightmost layer in the network. This fact restricts the application of this method from networks with a hidden layer. 

\subsection{Backpropargation}

The backpropargation algorithm is yet another learning rule for supervised networks, but in comparison to the hebbian and delta rules, it can also be applied for networks with $n$ numbers of hidden layers. There are certain problems that cannot be solved by networks without at least one hidden layer, the XOR-Gate being an famous example for such problems. I was first  by Paul Werbos in 1975 \cite{BACK} and consists of three main steps:
\begin{itemize}
\item[1.] \textbf{The forward-pass}:
A pattern is presented to the input layer and further propargated into the network.
\item[2.] \textbf{Error-determination}:\\
The observed output is compared to targeted result and an error $E$ is determined by a derivale error-function $\varphi$ shown in equation \eqref{eq:backerror}. The factor of $\frac{1}{2}$ is used to simplify the derivation by cancelling the exponent.

\begin{equation}
\varphi = \frac{1}{2} (t-o)^2
\label{eq:backerror}
\end{equation}
\item[3.] \textbf{Backward-pass}:\\
The error is propargated from the back of the network to the front, hence the name \textbf{Backpropargation}. The connection are updated independent from their influence to $E$, which guarantees a result $o$ that is closer to $t$, provided the same output is presented to the input layer.
\end{itemize}

A first approach on finding a method to changing all weights in a weight that will minimize the error is to find $E$ for all possible combinations of weights $W$. The combination $W_{min}$ with the smallest $E$ would be the perfect solution, an abolute minimum of the error. The problem of this approach is that the computitional effort to finding this solution is way to high, since $W_{min}$ would have to be found in a $n$-dimensonial  hyperplane (given the number of neurons $n$).\\

Instead, the weights are adjusted using the gradient descent, which does not need to know the complete hyperplane\marginpar{\textit{gradient descent}}. It starts with a random combination of weights for which the gradient is determinded. The gradient is the function of a scalar field which shows the rate of change and the direction of the greatest change in the form of a vector field. After the gradient is determined it will be stepped down at a given rate - the learning rate, meaning that the weights are adjusted. For this new combination of weights, the gradient is again determined and stepped down until a local (or global minimum) is found or a maximum amount of repetitions is reached.\\

The amount of change between neurons $i$ and $j$ $\delta w_{i,j}$ is calculated as shown in \eqref{eq:backrule}.
\begin{equation}
\Delta w_{i,j} = -\eta \frac{\partial E}{\partial w_{i,j}} = \eta \cdot \delta_j \cdot a_i
\label{eq:backrule}
\end{equation}
As distinct form the delta rule, the backpropargation rule differs two cases, shown in equation \eqref{eq:backcases}. $k$ is the index of the neurons in the subsequent layer.
\begin{equation}
   \delta_j =
   \begin{cases}
     \varphi'(in_j)(t_j-o_j) & \text{In case j is an output neuron} \\
     \varphi'(in_j)\sum_{k} \delta_k \cdot w_{j,k} & \text{In case j is a hidden neuron}
   \end{cases}
\label{eq:backcases}
\end{equation}

Eventuall the weights are changed acording to equation \eqref{eq:backweight}.

\begin{equation}
   w_{i,j}^{new} = w_{i,j}^{old} + \Delta w_{i,j}
\label{eq:backweight}
\end{equation}

\subsection{Backpropargation through time}
\subsection{Competitive learning}
%...
\section{Network tpyes}
\subsection{Feed Forward}
%...
\section{Applications}
\subsection{Pattern recognition}
%...

\KOMAoptions{listof=leveldown}

\newpage

%=========================================LISTS=========================================

\listoffigures
\listoftables
\listofalgorithms
\lstlistoflistings

\newpage

%=========================================DICTIONARY====================================

%dictiary style
\bibliographystyle{./files/alphadin}
%dictionary source
\bibliography{./files/bibdb}

\end{document}
